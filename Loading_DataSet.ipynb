{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 53,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.svm import LinearSVC\n",
<<<<<<< Updated upstream
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline"
=======
    "from sklearn.ensemble import RandomForestClassifier\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for reading the data files\n",
    "def build_data_frame(path):\n",
    "    rows = []\n",
    "    index = []\n",
    "    classification =[]\n",
    "    for file_name, text, classification in read_files(path):\n",
    "        rows.append({'text':text, 'class': classification})\n",
    "        index.append(file_name)\n",
    "        \n",
    "    data_frame = pd.DataFrame(rows,index=index)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    newline=''\n",
    "    for root, dir_names, file_names in os.walk(path):\n",
    "        print('Root folder: {0}'.format(root))\n",
    "        print('Number of files read: {0}'.format(len(file_names)))\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root,file_name)\n",
    "            if(os.path.isfile(file_path)):\n",
    "                #print(file_name)\n",
    "                if(\"D\" in file_name):\n",
    "                    label=\"D\"\n",
    "                elif(\"R\" in file_name):\n",
    "                    label=\"R\"\n",
    "                else:\n",
    "                    label=\"X\"\n",
    "                lines = []\n",
    "                f = open(file_path)\n",
    "                for line in f:\n",
    "                    lines.append(line.rstrip(\"\\n\"))\n",
    "                f.close()\n",
    "                content=newline.join(lines)\n",
    "                yield file_name, content, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder: /home/pk-user/Documents/IE594-Data-Science/Speech-classification/data_set\n",
      "Number of files read: 856\n"
     ]
    }
   ],
   "source": [
    "# here I set the path of data set using os.getcwd()\n",
    "path = os.path.join(os.getcwd(), 'data_set')\n",
    "# intitalize the empty data frame\n",
    "data = pd.DataFrame({'text':[],'class':[]})\n",
    "# call the function to build the data set\n",
    "data=data.append(build_data_frame(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parse file name, reorder columns and print to csv\n",
    "\n",
    "file_name = pd.Series(data.index.values)\n",
    "bill, speaker, meta_date, file_name= file_name.str.split('_').str\n",
    "data['bill_id'] = bill.values\n",
    "data['speaker_id'] = speaker.values\n",
    "data['meta_date'] = meta_date.values\n",
    "data = data[['meta_date', 'speaker_id', 'class', 'bill_id', 'text']]\n",
    "data.to_csv('clean_data.csv')"
   ]
  },
  {
<<<<<<< Updated upstream
=======
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "train_data, test_data = train_test_split(data, test_size = 0.1, stratify = data['class'])"
   ]
  },
  {
>>>>>>> Stashed changes
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for executing the task"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 87,
=======
   "execution_count": 18,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Running NB with (1, 1)-grams\n",
      "Running NB with (1, 2)-grams\n",
      "Running NB with (1, 3)-grams\n",
      "Running NB with (1, 4)-grams\n",
      "Running NB with (2, 2)-grams\n",
      "Running NB with (2, 3)-grams\n",
      "Running NB with (2, 4)-grams\n",
      "Running NB with (3, 3)-grams\n",
      "Running NB with (3, 4)-grams\n",
      "Running NB with (4, 4)-grams\n",
      "{(1, 1): 0.74844863885271162, (1, 2): 0.78515381403143014, (1, 3): 0.79139445493301019, (1, 4): 0.79436265169725551, (2, 2): 0.79281117231581644, (2, 3): 0.79311783343959719, (2, 4): 0.79995005336459424, (3, 3): 0.79057317325935494, (3, 4): 0.79100871367618741, (4, 4): 0.76572923216007249}\n"
=======
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.81      0.67      0.73        39\n",
      "          R       0.76      0.87      0.81        47\n",
      "\n",
      "avg / total       0.78      0.78      0.78        86\n",
      "\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# using Pipeline \n",
    "\n",
    "pipeline = Pipeline([\n",
<<<<<<< Updated upstream
    "    ('vectorizer', CountVectorizer()),\n",
=======
    "    ('vectorizer', CountVectorizer(ngram_range=(2,3))),\n",
>>>>>>> Stashed changes
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "f1_R = make_scorer(f1_score,pos_label='R')\n",
    "\n",
    "ngrams = [(1,1),(1,2),(1,3),(1,4),(2,2),(2,3),(2,4),(3,3),(3,4),(4,4)]\n",
    "ngram_scores = {}\n",
    "for ngram in ngrams:\n",
    "    print('Running NB with {0}-grams'.format(ngram))\n",
    "    pipeline.set_params(vectorizer__ngram_range=ngram)\n",
    "    score = cross_val_score(pipeline, data['text'], data['class'], cv=5, scoring=f1_R).mean()\n",
    "    ngram_scores[ngram] = score\n",
    "print(ngram_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with GridSearchCV with varying ngram_range and varying alpha"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 89,
=======
   "execution_count": 20,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "{'classifier__alpha': 0.5, 'vectorizer__ngram_range': (2, 3)}\n",
      "0.800772604187\n"
=======
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.86      0.31      0.45        39\n",
      "          R       0.62      0.96      0.76        47\n",
      "\n",
      "avg / total       0.73      0.66      0.62        86\n",
      "\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "pipeline.set_params(vectorizer__ngram_range=(2,4))\n",
    "param_grid = dict(classifier__alpha=[1, 0.5, 0.005,0.0005],vectorizer__ngram_range=[(1,3),(2,3),(2,4)])\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, scoring=f1_R, cv=5)\n",
    "grid_search.fit(data['text'], data['class'])\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using TfidfTransformer for further processing the ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73077083575890389"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using TfidTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',CountVectorizer(ngram_range=(2,4))),\n",
    "    ('tfidf_transformer',TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "pipeline.set_params(vectorizer__ngram_range=(1,3))\n",
    "score = cross_val_score(pipeline, data['text'], data['class'], cv=5, scoring=f1_R).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stratifiedKFold for cross validation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 35,
   "metadata": {},
>>>>>>> Stashed changes
   "outputs": [],
   "source": [
    "# using kfold for cross validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(2,4))),\n",
    "    #('tfidTransformer', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "skf = StratifiedKFold(n_splits =5)\n",
    "#confusion =[[0,0],[0,0]]\n",
    "scores=[]\n",
    "for train_index, test_index in skf.split(data['text'],data['class']):\n",
    "    train_text = data.iloc[train_index]['text'].values\n",
    "    train_y = data.iloc[train_index]['class'].values\n",
    "    \n",
    "    test_text = data.iloc[test_index]['text'].values\n",
    "    test_y = data.iloc[test_index]['class'].values\n",
    "    \n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "    #confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y,predictions,pos_label='R')\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71186440677966112"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
=======
   "execution_count": 36,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519182364951551"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(confusion)\n",
    "sum(scores)/len(scores)\n",
    "#print(sum(train_y=='D'))\n",
    "#print(sum(train_y=='R'))\n",
    "#print(len(train_y))\n",
    "#print(sum(data['class']=='D'))\n",
    "#print(sum(data['class']=='R'))\n",
    "#print(len(data['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create N-gram features\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "x_train = count_vectorizer.fit_transform(train_data['text'])\n",
    "y_train = train_data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 21]\n",
      " [ 5 42]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.78      0.46      0.58        39\n",
      "          R       0.67      0.89      0.76        47\n",
      "\n",
      "avg / total       0.72      0.70      0.68        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "#Test results\n",
    "x_test = count_vectorizer.transform(test_data['text'])\n",
    "y_test = test_data['class'].values\n",
    "predictions = classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.62      0.62      0.62        39\n",
      "          R       0.68      0.68      0.68        47\n",
      "\n",
      "avg / total       0.65      0.65      0.65        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "classifier_svc = LinearSVC()\n",
    "classifier_svc.fit(x_train, y_train)\n",
    "predictions_svc = classifier_svc.predict(x_test)\n",
    "print(classification_report(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.62      0.62      0.62        39\n",
      "          R       0.68      0.68      0.68        47\n",
      "\n",
      "avg / total       0.65      0.65      0.65        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(x_train, y_train)\n",
    "predictions_rf = classifier_svc.predict(x_test)\n",
    "print(classification_report(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Starting to create matrix for plot\n",
    "count_vectorizer_plot = CountVectorizer(ngram_range=(3, 3), max_features = 50)\n",
    "counts_plot = count_vectorizer_plot.fit_transform(data['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
