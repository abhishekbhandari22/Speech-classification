{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for reading the data files\n",
    "def build_data_frame(path):\n",
    "    rows = []\n",
    "    index = []\n",
    "    classification =[]\n",
    "    for file_name, text, classification in read_files(path):\n",
    "        rows.append({'text':text, 'class': classification})\n",
    "        index.append(file_name)\n",
    "        \n",
    "    data_frame = pd.DataFrame(rows,index=index)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    newline=''\n",
    "    for root, dir_names, file_names in os.walk(path):\n",
    "        print('Root folder: {0}'.format(root))\n",
    "        print('Number of files read: {0}'.format(len(file_names)))\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root,file_name)\n",
    "            if(os.path.isfile(file_path)):\n",
    "                #print(file_name)\n",
    "                if(\"D\" in file_name):\n",
    "                    label=\"D\"\n",
    "                elif(\"R\" in file_name):\n",
    "                    label=\"R\"\n",
    "                else:\n",
    "                    label=\"X\"\n",
    "                lines = []\n",
    "                f = open(file_path)\n",
    "                for line in f:\n",
    "                    lines.append(line.rstrip(\"\\n\"))\n",
    "                f.close()\n",
    "                content=newline.join(lines)\n",
    "                yield file_name, content, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root folder: /home/sadu/Documents/IE594-Data-Science/Speech-classification/data_set\n",
      "Number of files read: 856\n"
     ]
    }
   ],
   "source": [
    "# here I set the path of data set using os.getcwd()\n",
    "path = os.path.join(os.getcwd(), 'data_set')\n",
    "# intitalize the empty data frame\n",
    "data = pd.DataFrame({'text':[],'class':[]})\n",
    "# call the function to build the data set\n",
    "data=data.append(build_data_frame(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parse file name, reorder columns and print to csv\n",
    "\n",
    "file_name = pd.Series(data.index.values)\n",
    "bill, speaker, meta_date, file_name= file_name.str.split('_').str\n",
    "data['bill_id'] = bill.values\n",
    "data['speaker_id'] = speaker.values\n",
    "data['meta_date'] = meta_date.values\n",
    "data = data[['meta_date', 'speaker_id', 'class', 'bill_id', 'text']]\n",
    "data.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into train and test\n",
    "train_data, test_data = train_test_split(data, test_size = 0.1, stratify = data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create N-gram features\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "x_train = count_vectorizer.fit_transform(train_data['text'])\n",
    "y_train = train_data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 21]\n",
      " [ 5 42]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.78      0.46      0.58        39\n",
      "          R       0.67      0.89      0.76        47\n",
      "\n",
      "avg / total       0.72      0.70      0.68        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "#Test results\n",
    "x_test = count_vectorizer.transform(test_data['text'])\n",
    "y_test = test_data['class'].values\n",
    "predictions = classifier.predict(x_test)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.62      0.62      0.62        39\n",
      "          R       0.68      0.68      0.68        47\n",
      "\n",
      "avg / total       0.65      0.65      0.65        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "classifier_svc = LinearSVC()\n",
    "classifier_svc.fit(x_train, y_train)\n",
    "predictions_svc = classifier_svc.predict(x_test)\n",
    "print(classification_report(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          D       0.62      0.62      0.62        39\n",
      "          R       0.68      0.68      0.68        47\n",
      "\n",
      "avg / total       0.65      0.65      0.65        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(x_train, y_train)\n",
    "predictions_rf = classifier_svc.predict(x_test)\n",
    "print(classification_report(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Starting to create matrix for plot\n",
    "count_vectorizer_plot = CountVectorizer(ngram_range=(3, 3), max_features = 50)\n",
    "counts_plot = count_vectorizer_plot.fit_transform(data['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
